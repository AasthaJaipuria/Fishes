{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e804f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a8f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FishBase.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1196cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11898\n",
      "-----\n",
      "1 26221\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "fishRows = []\n",
    "i=0\n",
    "for idx in range(0,len(df)):\n",
    "    fish = {}\n",
    "    fish['ID'] = fId = df['ID'][idx]\n",
    "    fish['Species Name'] = df['Species'][idx]\n",
    "    \n",
    "    response = requests.get(\"https://www.fishbase.de/summary/{}\".format(fId)).text\n",
    "    soup = BeautifulSoup(response,'html.parser')\n",
    "    \n",
    "    print(i,fId)\n",
    "    i+=1\n",
    "    \n",
    "    if len(soup.find_all('p'))==0:\n",
    "        continue\n",
    "    \n",
    "    #----CommonName----\n",
    "    try:\n",
    "        fish['Common Name'] = soup.find(class_=\"sheader2\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "    #----AuthorName & Year----\n",
    "    author = [x.text for x in soup.find_all(class_='sheader6 noLinkDesign')]\n",
    "    fish['Authors'] = ', '.join(author[:-1])\n",
    "    fish['Year'] = author[-1]\n",
    "    \n",
    "    \n",
    "    #----Genus----\n",
    "    fish['Genus'] = df['Species'][idx].split()[0]\n",
    "\n",
    "    \n",
    "    #----Higher Taxon----\n",
    "    for x in soup.find_all(class_='sciname'):\n",
    "        try:\n",
    "            fish[x['title']] = x.text\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "    summary = soup.find_all(class_='smallSpace')\n",
    "    #----Environment,Habitat,Migration----\n",
    "    env_text = summary[1].text.strip()\n",
    "    env_list = env_text.split(';')\n",
    "    fish['Environment'] = env_list[0].strip()\n",
    "    try:\n",
    "        fish['Habitat'] = env_list[1].split('.')[0].strip()\n",
    "        fish['Migration'] = env_list[2].split('(Ref.')[0].strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----Depth Range----\n",
    "    depSt = env_text.find('depth range')\n",
    "    depEn = env_text.find('m',depSt)\n",
    "    if depSt!=-1:\n",
    "        fish['Depth Range'] = env_text[depSt+12:depEn]\n",
    "\n",
    "    \n",
    "    \n",
    "    #----pH Range----\n",
    "    pHSt = env_text.find('pH range:')\n",
    "    if pHSt!=-1:\n",
    "        pHEn = env_text.find(';',pHSt)\n",
    "        fish['pH'] = env_text[pHSt+9:pHEn].strip()\n",
    "\n",
    "    \n",
    "    \n",
    "    #----dH Range----\n",
    "    dHSt = env_text.find('dH range:')\n",
    "    if dHSt!=-1:\n",
    "        dHEn1 = env_text.find(';',dHSt)\n",
    "        dHEn2 = env_text.find('.',dHSt)\n",
    "        fish['dH'] = env_text[dHSt+9:min(dHEn1,dHEn2)].strip()\n",
    "\n",
    "    \n",
    "    \n",
    "    #----IUCN Red List Status & Threat----\n",
    "    boxlist = [x.parent.text.strip().split('(')[0] for x in soup.find_all(class_='box')]\n",
    "    fish['IUCN Status'] = boxlist[0]\n",
    "    try:\n",
    "        fish['Threat Level'] = boxlist[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "    #----Climate----\n",
    "    if \"Tropical\" in env_text:\n",
    "        fish['Climate'] = \"Tropical\"\n",
    "    elif \"Subtropical\" in env_text:\n",
    "        fish['Climate'] = \"Subtropical\"\n",
    "    elif \"Temperate\" in env_text:\n",
    "        fish['Climate'] = \"Temperate\"\n",
    "    elif \"Polar\" in env_text:\n",
    "        fish['Climate'] = \"Polar\"\n",
    "\n",
    "    \n",
    "    \n",
    "    #----Distribution----\n",
    "    dist = summary[2].text.strip().split(':')\n",
    "    fish['Area'] = dist[0].split('(Ref.')[0].split('.')[0]\n",
    "    \n",
    "    \n",
    "    #----Max Length----\n",
    "    physChars = summary[3].text.strip()\n",
    "    lenSt = physChars.find(\"Max length :\")\n",
    "    if lenSt!=-1:\n",
    "        lenEnd = physChars.find(\"cm\",lenSt)\n",
    "        fish['Max Length'] = physChars[lenSt+12:lenEnd].strip()\n",
    "\n",
    "    \n",
    "    \n",
    "    #----Max Published Weight----\n",
    "    wtSt = physChars.find(\"max. published weight: \")\n",
    "    if wtSt!=-1:\n",
    "        wtEnd = physChars.find(\"g\",wtSt+23)\n",
    "        fish['Max Weight'] = physChars[wtSt+23:wtEnd+1].strip()\n",
    "\n",
    "    \n",
    "    \n",
    "    #----Max Reported Age----\n",
    "    ageSt = physChars.find(\"max. reported age:\")\n",
    "    if ageSt!=-1:\n",
    "        ageEnd = physChars.find(\"year\",ageSt)\n",
    "        fish['Max Age'] = physChars[ageSt+18:ageEnd].strip()\n",
    "\n",
    "    \n",
    "    \n",
    "    #----Mode of Reproduction----\n",
    "    reproResponse = requests.get(\"https://www.fishbase.de/Reproduction/FishReproSummary.php?ID={}\".format(fId)).text\n",
    "    reproSoup = BeautifulSoup(reproResponse,'html.parser')\n",
    "    modeTag = reproSoup.find('tr',{\"class\":\"\"})\n",
    "    try:\n",
    "        fish['Mode of Reproduction'] = list(modeTag.stripped_strings)[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "    #----Fertilization Type----\n",
    "    try:\n",
    "        fish['Fertilization'] = list(modeTag.next_sibling.next_sibling.stripped_strings)[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    #----Human Uses----\n",
    "    uses = soup.find_all(class_='smallSpace')[12].text.strip()\n",
    "    usesDict = {}\n",
    "    if uses != '' and uses[:3] != 'FAO':\n",
    "        for use in uses.split(';'):\n",
    "            attr = use.split(':')\n",
    "            usesDict[attr[0].strip().lower()] = attr[1].strip()\n",
    "        fish.update(usesDict)\n",
    "\n",
    "    \n",
    "\n",
    "    #----Image----\n",
    "    fish['Image'] = 'https://www.fishbase.de/'+soup.find('a', {'style':\"text-decoration:none;\"}).img['src']\n",
    "    \n",
    "    \n",
    "    #----Image Credits----\n",
    "    picDes = soup.find(class_='slabel8').text\n",
    "    picSt = picDes.find(\"icture by\\r\\n\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\")\n",
    "    picEnd = picDes.find('\\n',picSt+24)\n",
    "    if picSt!=-1:\n",
    "        fish['Img Credits'] = picDes[picSt+23:picEnd].strip()\n",
    "    \n",
    "    \n",
    "    #----Main Reference----\n",
    "    mainRef = soup.find('span',string = 'References')\n",
    "    fish['Reference'] = mainRef.parent.parent.parent.div.text.strip()\n",
    "    \n",
    "    #----Environment Section----\n",
    "    fish['Env Section'] = env_text\n",
    "            \n",
    "    fishRows.append(fish)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557c1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterFish = pd.DataFrame.from_dict(fishRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterFish.to_csv(\"Master.csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ad976",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterFish.to_pickle(\"Master.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
